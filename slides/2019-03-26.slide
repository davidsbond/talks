I wrote my own programming language and you can too!

26 Mar 2019
Tags: interpreter, golang, ast, lexer, parser

David Bond
Software Engineer
davidsbond93@gmail.com
http://davidsbond.github.io/
@DaviiBond

* What I made:

A simple, interpreted programming language, written in Go.

  func main() {
    try {
      results := await {
        add(1, 2)
        add(3, 4)
        add(5, 6)
      }

      // Print the results
      print(results[0], results[1], results[2])
    } catch(err) {
      print(err)
    }
  }

  async func add(x, y) {
    return x + y
  }

.link https://github.com/davidsbond/zap

: Language works more or less exactly as JavaScript does
: Supports, async/await, try/catch, control flow, loops, functions as first class values, comments, built-in functions etc.

* Why use go?

- Take advantage of the existing garbage collector
- Simple concurrency model allows you to easily add concurrency to the language (`chan` native and `sync` package)
- Streaming interfaces (`io.Reader` etc.) allow for efficient parsing of source code
- Interpreter compiles to a single binary and is multi-platform out of the box
- Native type `rune` for representing unicode code points

  fmt.Println([]byte("日abc")) // [230 151 165 97 98 99]
  fmt.Println([]rune("日abc")) // [26085 97 98 99]

: The rune type is an alias for int32, and is used to emphasize that an integer represents a code point.
: For example, in the string "日abc" the character 日 (code point 26085) is encoded using three bytes, while the ASCII characters a, b and c (code points 97, 98 and 99) only use one
: Saves additional logic when iterating over characters. Allows expanding valid syntax with UTF-8 symbols.
: This kind of functionality is very useful if you want to include mathematical language (like Julia)

* What is an interpreter?

Nearly all interpreters boil down to three layers:

- The lexer
- The parser
- The evaluator

: An interpreted language is a type of programming language for which most of its implementations execute instructions directly and freely, without previously compiling a program into machine-language instructions. 
: The interpreter executes the program directly, translating each statement into a sequence of one or more subroutines, and then into another language (often machine code).
: Popular example is JavaScript, with different interpreter implementations V8 (Chrome, C++) and SpiderMonkey (Mozilla, C/C++)

* Implementing the lexer

Main responsibilities of a lexer:

- Read source code character by character
- Convert characters into lexemes
- Convert lexemes into tokens
- Returning errors when invalid characters are used

: The lexer (lexical analyzer or tokenizer) is a program that breaks down the input source code into a sequence of lexemes. 
: It reads the input source code character by character, recognizes the lexemes and outputs a sequence of tokens describing the lexemes.
: A lexeme is a single identifiable sequence of characters (keywords: func, var, for), literals (numbers, strings etc.), identifiers, operators, or punctuation characters ({, (, and .).
: A token is an object describing the lexeme. 
: A token has a type (e.g. Keyword, Identifier, Number, or Operator) and a value (the actual characters of the described lexeme). 
: A token can also contain other information such as the line and column numbers where the lexeme was encountered in the source code.

* 

What this looks like, is a huge `switch` statement

  char := string(l.currentChar)

  switch char {
  case '(':
    // Tokens are stored in constants
    tok = l.newToken(token.LPAREN, char)
  case ')':
    tok = l.newToken(token.RPAREN, char)
  case ',':
    tok = l.newToken(token.COMMA, char)
  case '=':
    // Check if we're assigning (=) or comparing (==)
    if l.peekChar() == '=' {
      l.readChar()
      tok = l.newToken(token.EQ, char)
    } else {
      tok = l.newToken(token.ASSIGN, char)
    }
    // And so on for all possible tokens we want to use...
  }

.link https://github.com/davidsbond/zap/blob/master/lexer/lexer.go source

: Talk about all source code being samples, links to source files will be provided for each snippet

* Implementing the parser

The parser is responsible for:

- Converting the tokens into an abstract syntax tree
- Understanding operator precedence
- Understanding prefixes (-, +), infixes (>, <) & postfixes (++, --)
- Returning errors when presented with invalid syntax

: An AST is a tree representation of the abstract syntactic structure of source code written in a programming language. 
: Each node of the tree denotes a construct occurring in the source code (if statement, for loop etc.)
: The syntax is "abstract" in the sense that it does not represent every detail appearing in the real syntax, but rather just the structural, content-related details.
: Operator precedence is just BIDMAS for logical/binary operators
: Infix, Postfix and Prefix notations are three different but equivalent ways of writing expressions.

* 

Turns out, this also looks like a huge `switch` statement

  switch p.currentToken.Type() {
  case token.USE:
    return p.parseUseStatement()
  case token.VAR:
    return p.parseVarStatement()
  case token.RETURN:
    return p.parseReturnStatement()
  case token.ASYNC:
    return p.parseAsyncLiteral()
  case token.FUNCTION:
    return p.parseFunctionLiteral()
    // And so on for all possible tokens we want to use...
  }

.link https://github.com/davidsbond/zap/blob/master/parser/parser.go source

: Literals are where we define something like a function, async function etc.
: Statements are declarations like variable assignments, importing other files etc.

* 

Where methods iterate through tokens until the expression is complete:

  stmt := ast.NewVarStatement(p.currentToken, p.peekTokenIs(token.VARASSIGN))
  stmt.SetName(p.currentToken)

  // If we don't have a '=' or ':=' character here, something is amiss!
  if !p.expectPeek(token.VARASSIGN) && !p.expectPeek(token.ASSIGN) {
    return nil
  }

  p.nextToken()

  // The next token should be some sort of value we assign to a variable, parse
  // it with the lowest precedence
  value := p.parseExpression(LOWEST)
  stmt.SetValue(value)


.link https://github.com/davidsbond/zap/blob/master/parser/var_expression.go source

: This source code shows how a variable declaration/assignment is parsed from tokens.
: We use 'expectPeek' to check the next function is what we expect, this is used for simple validation
: We use 'nextToken' to move to the next token
: Basically everything is an expression that can be parsed.

* 

Then create data structures representing the branching logic of the source code

  type (
    // The IfExpression type represents an if statement within the syntax
    // tree. An if statement consists of a condition, consequence and an optional
    // alternative.
    //
    // if (something) {			<-- Condition
    // 	return true			 <-- Consequence
    // } else {
    //	return false		     <-- Alternative
    // }
    //
    IfExpression struct {
      token       token.Token
      condition   Expression
      consequence *BlockStatement
      alternative *BlockStatement
    }
  )

.link https://github.com/davidsbond/zap/blob/master/ast/if_expression.go source

* Implementing the evaluator

The evaluator is responsible for:

- Traversing the abstract syntax tree
- Converting literals into objects in memory
- Managing scope
- Executing statements and storing their result in memory, passing them back up the AST for further evaluation
- Handling built-in function calls (`length()`, `env()` etc.)
- Understanding how types are used together

* 

If you didn't already guess, it's another huge switch statement

  switch node := node.(type) {
  // We get another AST when we have a 'use' import.
  case *ast.AST:
    for _, stmt := range node.Statements() {
      if err, ok := eval(stmt, scope).(*object.Error); ok {
        return err
      }
    }

    return NULL
  // Use recursion to evaluate the underlying expression when
  // evaluating an expression statement
  case *ast.ExpressionStatement:
    return eval(node.Expression(), scope)

  // When evaluating a number literal, create a new object
  // with the node value
  case *ast.NumberLiteral:
    return object.NewNumber(node.Value())
  // And so on for every type of node we support in the AST

.link https://github.com/davidsbond/zap/blob/master/evaluator/evaluator.go source

* 

Where we go through the nodes in the AST and do appropriate evaluation for each type

  func evalIfExpression(exp *ast.IfExpression, scope *object.Scope) object.Object {
    cond := eval(exp.GetCondition(), scope)

    if cond == TRUE {
      return eval(exp.GetConsequence(), scope)
    }

    if cond == FALSE && exp.GetAlternative() != nil {
      return eval(exp.GetAlternative(), scope)
    }

    return NULL
  }

.link https://github.com/davidsbond/zap/blob/master/evaluator/if_statement.go source

* 

- In scenarios where we have operations on different types, we need to explicitly define the behavior.
- When I use an index accessor on a `string`, I expect an instance of `character` back

  str, _ := strObj.(*object.String)
  idx, _ := index.(*object.Number)

  // Get the index and value of the string
  strVal := str.Value()
  indxVal := int(idx.Value())
  indxChar := strVal[indxVal]

  // Create a new character instance
  return object.NewCharacter(indxChar)

.link https://github.com/davidsbond/zap/blob/master/evaluator/index_expression.go source

* What's in an object?

- All in-memory data structures are implementations of the `Object` interface
- Using an interface it's easy to add new native types, allowed me to add `Character` and `String` as different types
- We can provide a built-in function to allow type comparison, similar to `typeOf`

* 

In total the native types are:

- Boolean 
- String
- Character 
- Number
- Error 
- Function
- Map 
- Array 
- Builtin
- Null

* What are built-in functions?

- Identifiers that correspond to functions in the interpreter. 

  func Type(node ast.Node, args ...object.Object) object.Object {
    if len(args) != 1 {
      return object.NewError("Function 'type' only takes 1 argument", node.Token())
    }

    arg := args[0]

    return object.NewString(string(arg.Type()))
  }

.link https://github.com/davidsbond/zap/blob/master/builtin/type.go source

* 

They can be called as regular methods as they exist in the global scope

  // Sample for testing the built-in type function
  func main() {
      str := type("a test string")
      map := type({ "key": "a map" })
      num := type(1.337)
      chr := type('a')
  }

.link https://github.com/davidsbond/zap/blob/master/samples/type.zap source

: For example, a method to compare types of objects.
: The method is not part of the standard library, but a call to the underlying interpreter

* How does the evaluator manage scope?

- The scope is just a map containing all objects available to an expression.
- These objects can be variables, methods, built-in functions etc.
- We check the most specific scope first before checking the parent.

  // Create a child scope for this method call that contains
  // the evaluated arguments. This way, once we finish calling
  // the method, the evaluated arguments do not exist in the parent
  // scope and can be disposed by the GC
  innerScope := scope.NewInnerScope()
  
  for i, param := range function.GetParameters() {
    innerScope.Set(param.Name(), args[i])
  }

  //...
  // Then evaluate the method body using the new scope
  result = eval(function.GetBody(), innerScope)

.link https://github.com/davidsbond/zap/blob/master/evaluator/call_expression.go source

: Using this scope model means you can reuse names of objects from the parent scope without overriding them
: Literally just a map